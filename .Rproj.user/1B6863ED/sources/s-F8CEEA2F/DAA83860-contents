rm(list=ls())
library(dplyr)
library(tidyr)
library(data.table)
library(xtable)
library(knitr)
library(countrycode)
library(lfe)
library(grid)
library(gridExtra)
library(ggplot2)
library(readxl)
library(broom)
library(AER)
library(texreg)
library(mFilter)
library(stargazer)
library(splines)
#-------------------------------------------------------------------------------------------------------------------#
# Clean the monthly price data from FAOSTAT. 
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#
{
file <- list.files(path = '../5_Data/FAOPriceDataRaw/', pattern = '.csv')
dat <- lapply(file, function(i) read.csv(paste0('../5_Data/FAOPriceDataRaw/', i), header = T))
  
clean_dat_func <- function(dat1){
    if(ncol(dat1) <= 2){
      dat1 <- data.frame(Time = NA, ID = NA, Value = NA)
    }else{
      colnames(dat1)[1] <- 'Time'
      dat1 <- dat1 %>%
        gather(ID, Value, 2:ncol(.)) %>%
        mutate(Value = as.numeric(Value),
               Time = as.character(Time))
    }
    dat1
}
  
datClean <- lapply(dat, clean_dat_func) %>%
    bind_rows()
  
tmp <- datClean %>%
    filter(grepl('US', ID)) %>%
    select(-Value, - Time) %>%
    distinct() %>%
    mutate(IDSplit = strsplit(ID, split = '..', fixed = T),
           Country = NA,
           MarketChain = NA,
           City = NA,
           Commodity = NA,
           Character = NA)
  
  for (i in 1:nrow(tmp)){
    tmp$Country[i] <- tmp$IDSplit[i][[1]][1]
    tmp$MarketChain[i] <- tmp$IDSplit[i][[1]][2]
    tmp$City[i] <- tmp$IDSplit[i][[1]][3]
    tmp$Commodity[i] <- tmp$IDSplit[i][[1]][4]
    tmp$Character[i] <- tmp$IDSplit[i][[1]][5]
  }
  
  tmp <- tmp %>%
    mutate(Commodity = ifelse(grepl('aize', Commodity), 'Maize', Commodity),
           Commodity = ifelse(grepl('Rice', Commodity), 'Rice', Commodity),
           Commodity = ifelse(grepl('Wheat', Commodity), 'Wheat', Commodity),
           Commodity = ifelse(grepl('oriental', Commodity), 'Rice', Commodity)) # Personal check


datClean2 <- datClean %>%
  filter(grepl('US', ID), !grepl('Italy', ID), !grepl('Palestinian', ID)) %>%
  left_join(., tmp, by = 'ID') %>%
  select(-IDSplit) %>%
  mutate(TimeFM = as.Date(paste0('01-', Time), format = '%d-%b-%y'),
         Country = ifelse(Country == 'Eswatini', 'Swaziland', Country)) %>%
  mutate(Year = year(TimeFM), Month = month(TimeFM)) %>%
  select(-Time) %>%
  mutate(ISO = countrycode(Country, 'country.name', 'iso3c')) %>%
  filter(Commodity == 'Maize', Value <= 50)
# This filtering procedure will naturally rule out the observations
# that are in US dollar per tonne. We use the data on US dollar per kg.

#------------------------------------------------------------------------------#
# Check for duplicates. 
checkData1 <- datClean2 %>%
  group_by(ID, TimeFM) %>%
  summarise(Num = n())

checkData2 <- datClean2 %>%
  group_by(Country, City, Commodity, Character, MarketChain, TimeFM) %>%
  summarise(Num = n()) %>%
  filter(Num > 1) 

test <- filter(datClean2, Country == 'Mexico', City == 'Mexico.City', Character == 'white')

# This shows that some price series with same selectec attributes might be
# duplicated due to some differences (reflected in ID column)
# Consider this case, we take the monthly averages of two different series. 

# Extract the series with unique series for the single group
uniquePriceSeries <- datClean2 %>% 
  group_by(Country, City, Commodity, Character, MarketChain, TimeFM) %>%
  summarise(NumOfObs = n()) %>%
  filter(NumOfObs == 1)

duplicatedPriceSeries <- datClean2 %>% 
  group_by(Country, City, Commodity, Character, MarketChain, TimeFM) %>%
  summarise(NumOfObs = n()) %>%
  filter(NumOfObs > 1) %>%
  left_join(., datClean2, by = c('Country', 'City', 'Commodity', 'Character', 'MarketChain', 'TimeFM')) %>%
  group_by(ID, Country, City, Commodity, Character, MarketChain) %>%
  summarise(Num = n()) 
# All series have the same length, so averaging should not be a problem. 


# Averaging prices with different attributes for the same group. 
datClean3 <- datClean2 %>% 
  group_by(Country, City, Commodity, Character, MarketChain, TimeFM) %>%
  summarise(Value = mean(Value), NumOfObs = n()) %>%
  mutate(Year = year(TimeFM), Month = month(TimeFM))

write.csv(datClean3, file = '../5_Data/FAOMaizeMonthPriceMay.csv', row.names = F)
}
#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<#


#-------------------------------------------------------------------------------------------------------------------#
# Study the seasonality in the prices. 
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#
rm(list = ls())

# Select the importing countries. 
selCtys <- c('Chile', 'China', 'Colombia', 'Ecuador', 'El.Salvador', 'Guatemala', 'Honduras', 'Mexico',
             'Nicaragua', 'Panama', 'Peru', 'Philippines', 'Uruguay', 'Angola', 'Burundi', 'Cabo.Verde',
             'Cameroon', 'Chad', 'Ghana', 'Kenya', 'Mozambique', 'Namibia', 'Rwanda', 'Swaziland')

rawData <- fread('../5_Data/FAOMaizeMonthPriceMay.csv') %>% mutate(TimeFM = as.Date(TimeFM, format = '%Y-%m-%d'))
deflator <- fread('../5_Data/Fred_US_CPI_May2019.csv', stringsAsFactors = TRUE) %>%
  'colnames<-'(c('Date', 'CPI')) %>%
  mutate(Date = as.Date(Date, format = '%Y-%m-%d'))

# Test consistency with FAOGIEWS dataset
test <- filter(rawData, Country == 'Nicaragua')

# Deflate the prices using the US CPI. 
PriceMonthDat <- rawData %>%
  left_join(., deflator, by = c('TimeFM' = 'Date')) %>%  # Modified on 04/24/2018.
  mutate(Value = 100*Value/CPI) %>%
  mutate(logValue = log(Value)) %>%
  filter(Country %in% selCtys)

# Create a table that produces summary statistics of the price data by country. 
priceSummary <- PriceMonthDat %>%
  group_by(Country) %>%
  summarise(Min = min(Value), Mean = mean(Value), Median = median(Value),
            Max = max(Value), SD = sd(Value)) %>%
  mutate(CV = SD/Mean) %>%
  mutate_if(is.numeric, round, 2)

# Export to Latex
stargazer(priceSummary, summary = FALSE)


# Detrend the price data using the HP filter and CF filter. 
linearTrendFunc <- function(x, y) lm(x ~ y)$residual
quadraticTrendFunc <- function(x, y) lm(x ~ poly(y, 2))$residual
cubicTrendFunc <- function(x, y) lm(x ~ poly(y, 3))$residual
splineTrendFunc <- function(x, y) lm(x ~ bs(y, 3, degree = 2))$residual

# Focus on log prices. 
selPriceData <- PriceMonthDat %>%
  filter(Country %in% selCtys, Commodity == 'Maize') %>%
  mutate(Group = paste0(City, MarketChain, Character)) %>%
  #filter(Group == selGroup) %>%
  group_by(Country, Group) %>%
  arrange(TimeFM, .by_group = TRUE) %>%
  mutate(Trend = 1:n(),
         deTrendHP = hpfilter(logValue, freq = 129600, type = 'lambda')$cycle,
         deTrendCF = cffilter(logValue, pl = 2, pu = 8, type = 'asymmetric')$cycle,
         deTrendLinear = linearTrendFunc(logValue, Trend),
         deTrendQuadratic = quadraticTrendFunc(logValue, Trend),
         deTrendCubic = cubicTrendFunc(logValue, Trend),
         deTrendSpline = splineTrendFunc(logValue, Trend)) %>%
  mutate(cosValue = cos(Month*pi/6), sinValue = sin(Month*pi/6))

# summary(selPriceData)

# identical(selPriceData, selPriceData2)
# selPriceData$City == selPriceData2$City
test <- c('Philippines', 'MetroManilaRetailyellow')
testData <- selPriceData %>% filter(Country == test[1], Group == test[2]) 

plot(testData$logValue, type = 'p')
lines(testData$logValue - testData$deTrendHP, col = 'red')
lines(testData$logValue - testData$deTrendSpline, col = 'blue')
lines(testData$logValue - testData$deTrendQuadratic, col = 'green')
lines(testData$logValue - testData$deTrendCubic, col = 'purple')

# sum((testData$logValue - mean(testData$logValue))^2)
# sum((testData$deTrendHP - mean(testData$logValue))^2)
# sum((testData$deTrendCF - mean(testData$logValue))^2)
 
# sum(testData$deTrendCF^2)
# sum(testData$deTrendHP^2)

# Variation explained by trend. 
varRatio <- selPriceData %>%
  group_by(Country, Group) %>%
  summarise(HPTrendRatio = 1 - sum(deTrendHP^2)/sum((logValue - mean(logValue))^2),
            CFTrendRatio = 1 - sum(deTrendCF^2)/sum((logValue - mean(logValue))^2),
            LinearTrendRatio = 1 - sum(deTrendLinear^2)/sum((logValue - mean(logValue))^2),
            QuadraticTrendRatio = 1 - sum(deTrendQuadratic^2)/sum((logValue - mean(logValue))^2),
            CubicTrendRatio = 1 - sum(deTrendCubic^2)/sum((logValue - mean(logValue))^2),
            SplineTrendRatio = 1 - sum(deTrendSpline^2)/sum((logValue - mean(logValue))^2)) %>%
  mutate_if(is.numeric, function(x) {round(100*x, 2)})

# Exclude the seasonality from the data. 
### Look at the data with HP trend. 
x <- 'Linear'

deSeasonFunc <- function(x){
selPriceDataSeason1 <- selPriceData %>%
  group_by(Country, Group) %>%
  do(fitSeason = lm(formula(paste0('deTrend', x,  '~ cosValue + sinValue')), data = .)) 

selPriceDataSeason2 <- augment(selPriceDataSeason1, fitSeason) %>%
  ungroup() %>%
  mutate(TimeFM = selPriceData$TimeFM) %>%
  select(1:3, 6, 8, 13) %>%
  rename(!!paste0(x, '.resid') := .resid, !!paste0(x, '.fitted') := .fitted) 

selPriceDataSeason2Stat <- glance(selPriceDataSeason1, fitSeason) %>%
  select(1:2, r.squared, statistic, p.value) %>%
  rename(!!paste0(x, '.r.squared') := r.squared, 
         !!paste0(x, '.statistic') := statistic,
         !!paste0(x, '.p.value') := p.value) 

selPriceDataSeason2 <- selPriceDataSeason2 %>%
  left_join(., selPriceDataSeason2Stat, by = c('Country', 'Group'))

selPriceDataSeason2
}

DeSeason1 <- deSeasonFunc(x = 'Linear')  
DeSeason2 <- deSeasonFunc(x = 'HP')  
DeSeason3 <- deSeasonFunc(x = 'CF')  
DeSeason4 <- deSeasonFunc(x = 'Quadratic')  
DeSeason5 <- deSeasonFunc(x = 'Cubic')  
DeSeason6 <- deSeasonFunc(x = 'Spline')  

DeSeasonData <- DeSeason1 %>%
  full_join(., DeSeason2, by = c('Country', 'Group', 'TimeFM')) %>%
  full_join(., DeSeason3, by = c('Country', 'Group', 'TimeFM')) %>%
  full_join(., DeSeason4, by = c('Country', 'Group', 'TimeFM')) %>%
  full_join(., DeSeason5, by = c('Country', 'Group', 'TimeFM')) %>%
  full_join(., DeSeason6, by = c('Country', 'Group', 'TimeFM')) %>%
  full_join(., select(selPriceData, 1:7, logValue, Group), by = c('Country', 'Group', 'TimeFM'))
  
# show the original data in logs.
selCty <- selCtys[1]

DeSeasonData %>%
  filter(Country == selCty) %>%
  select(Group, TimeFM, logValue, contains('.fitted')) %>%
  gather(Variable, Value, 3: ncol(.)) %>%
  ggplot(data = .) +
  geom_line(aes(TimeFM, Value, col = Variable))


write.csv(DeSeasonData, file = '../5_Data/FAOMaizeMonthPriceDeTrendDeSeasonAllTypes_May2019.csv', row.names = F)

# # Variation explained by seasonality. 
# varRatio2_CF <- selPriceDataSeasonCF2 %>%
#   group_by(Country, Group) %>%
#   summarise(CFSeasonRatio = sum((.fitted - mean(.fitted))^2)/sum((logValue - mean(logValue))^2))
# 
# varRatio2 <- varRatio2_HP %>%
#   left_join(., varRatio2_CF, by = c('Country', 'Group')) %>%
#   left_join(., varRatio, by = c('Country', 'Group'))
# 
# write.csv(varRatio2, file = '../5_Data/VarExplainSeasonality.csv', row.names = F)
# 
# 
# reg2 <- lm(Value ~ Trend + cosValue + sinValue, data = testSel)
# summary(reg2)
# 
# coefEst2 <- reg2$coefficients
# 
# sqrt(coefEst2['cosValue']^2 + coefEst2['sinValue']^2)
# 
# seasonalityFunc <- function(x) coefEst2['cosValue']*cos(x*pi/6) + coefEst2['sinValue']*sin(x*pi/6)
# plot(c(1:12), seasonalityFunc(c(1:12)))
# lines(c(1:12), seasonalityFunc(c(1:12)))

  
# Check for consistency
# summary(selPriceDataSeasonAll)
# sd(abs(selPriceDataSeasonAll$tmp1)) == 0
# all.equal(sd(abs(selPriceDataSeasonAll$tmp2)), 0) # There could be minor discrepancy due to rounding error. 
# 
# # If the data are consistent,
# selPriceDataSeasonAll <- selPriceDataSeasonAll %>%
#   rename(deTrendHP = deTrendHP.x) %>%
#   select(-deTrendHP.y, -tmp1, -tmp2, -cosValue, -sinValue, -Trend, -CPI) 
# 
# write.csv(selPriceDataSeasonAll , file = '../5_Data/FAOMaizeMonthPriceDeTrendDeSeason_May2019.csv', row.names = F)
#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<#


#-------------------------------------------------------------------------------------------------------------------#
# Calculate the intra-annual food price variability. 
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#
rm(list = ls())

selPriceData <- fread('../5_Data/FAOMaizeMonthPriceDeTrendDeSeasonAllTypes_May2019.csv') %>%
  mutate(ISO = countrycode(Country, 'country.name', 'iso3c')) %>%
  mutate(TimeFM = as.Date(TimeFM, format = '%Y-%m-%d')) %>%
  mutate(Year = year(TimeFM), Month = month(TimeFM))

# Marketing Year
{
MarketYearMaize <- read_xls('../5_Data/PSD_MarketYear/PSD_MarketYearMaize.xls', sheet = 1, range = 'A2:D227') %>%
  mutate(Commodity = 'Maize') %>%
  filter(grepl('2018', Years)) %>%
  mutate(StartYear = substr(Years, 1, 4), EndYear = substr(Years, 6, 9),
         StartMonth = match(tolower(substr(`Market Year`, 1, 3)), tolower(month.abb)),
         EndMonth = match(tolower(substr(`Market Year`, 8, 10)), tolower(month.abb)),
         YearAdjust = ifelse(substr(`Note`, 6, 9) == substr(`Note`, 35, 38), 'Same', 'Onwards'),
         ISO = countrycode(Country, 'country.name', 'iso3c')) %>%
  dplyr::select(5, 8, 9, 10, 11)

### Add marketing year information to the dataset.
AddDat <- data.frame(matrix(NA, 2, 5))
colnames(AddDat) <- colnames(MarketYearMaize)
AddDat[1, ] <- c('Maize', 7, 6, 'Same', 'SWZ') # Swaiziland
AddDat[2, ] <- c('Maize', 7, 6, 'Same', 'NER') # Niger
AddDat$StartMonth <- as.numeric(AddDat$StartMonth)
AddDat$EndMonth <- as.numeric(AddDat$EndMonth)

MarketYearMaize <- bind_rows(MarketYearMaize, AddDat)
}

# Merge with the market year information.
selPriceDataIntraX1 <- selPriceData %>%
  left_join(., MarketYearMaize, by = c('ISO')) %>%
  mutate(mktYear = ifelse(Month < StartMonth, Year - 1, Year)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear) %>%
  select(contains('.resid'), contains('Trend'), logValue) %>% # Warning of adding missing variable is expected. 
  gather(Variable, Value, 7:ncol(.)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear, Variable) %>%
  summarise(priceSD = sd(Value),
            Num = n()) %>%
  filter(Num > 6) %>%
  mutate(Variable = paste0(Variable, '.SD')) %>%
  spread(Variable, priceSD)

# Standard deviation of log changes. 
selPriceDataIntraX2 <- selPriceData %>%
  left_join(., MarketYearMaize, by = c('ISO')) %>%
  mutate(mktYear = ifelse(Month < StartMonth, Year - 1, Year)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear) %>%
  select(Month, logValue) %>%
  arrange(Month, .by_group = T) %>%
  mutate(changeLogValue = logValue - dplyr::lag(logValue)) %>%
  summarise(SDlogChange = sd(changeLogValue, na.rm = T))

selPriceDataIntraX3 <- selPriceData %>%
  left_join(., MarketYearMaize, by = c('ISO')) %>%
  mutate(mktYear = ifelse(Month < StartMonth, Year - 1, Year)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear) %>%
  select(contains('.resid'), contains('Trend'), logValue) %>% # Warning of adding missing variable is expected. 
  gather(Variable, Value, 7:ncol(.)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear, Variable) %>%
  summarise(priceGap = max(Value) - min(Value),
            Num = n()) %>%
  filter(Num > 6) %>%
  mutate(Variable = paste0(Variable, '.Gap')) %>%
  spread(Variable, priceGap)

selPriceDataIntraX4 <- selPriceData %>%
  left_join(., MarketYearMaize, by = c('ISO')) %>%
  mutate(mktYear = ifelse(Month < StartMonth, Year - 1, Year)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear) %>%
  select(contains('.resid'), contains('Trend'), logValue) %>% # Warning of adding missing variable is expected. 
  gather(Variable, Value, 7:ncol(.)) %>%
  group_by(ISO, Country, City, MarketChain, Group, mktYear, Variable) %>%
  summarise(priceGap = IQR(Value),
            Num = n()) %>%
  filter(Num > 6) %>%
  mutate(Variable = paste0(Variable, '.IQR')) %>%
  spread(Variable, priceGap)


selPriceDataIntra <- selPriceDataIntraX1 %>%
  left_join(., selPriceDataIntraX2, by = c('ISO', 'Country', 'City', 'MarketChain', 'Group', 'mktYear')) %>%
  left_join(., selPriceDataIntraX3, by = c('ISO', 'Country', 'City', 'MarketChain', 'Group', 'mktYear')) %>%
  left_join(., selPriceDataIntraX4, by = c('ISO', 'Country', 'City', 'MarketChain', 'Group', 'mktYear'))

summary(selPriceDataIntra)

write.csv(selPriceDataIntra , file = '../5_Data/FAOMaizePriceMktYearVAR_May2019.csv', row.names = F)


# reg2 <- lm(Value ~ Trend + cosValue + sinValue, data = testSel)
# summary(reg2)
# 
# coefEst2 <- reg2$coefficients
# 
# sqrt(coefEst2['cosValue']^2 + coefEst2['sinValue']^2)
# 
# seasonalityFunc <- function(x) coefEst2['cosValue']*cos(x*pi/6) + coefEst2['sinValue']*sin(x*pi/6)
# plot(c(1:12), seasonalityFunc(c(1:12)))
# lines(c(1:12), seasonalityFunc(c(1:12)))

# Visualize the intra-annual maize price variability. 
# Compare the distribution of intra-annual maize price variability across different measures. 
selPriceDataIntra %>%
  select(-contains('CF')) %>%
  gather(Variable, Value, 8:ncol(.)) %>%
  ggplot(data = .) +
  geom_boxplot(aes(Variable, Value)) 

# Show the intra-annual maize price variability across different focus countries. 
selPriceDataIntra %>%
  ggplot(data = .) +
  geom_boxplot(aes(Country, Quadratic.residSD))

selPriceDataIntra %>%
  filter(mktYear >= 2000) %>%
  ggplot(data = .) +
  geom_boxplot(aes(mktYear, Quadratic.residSD, group = mktYear))

# Create a table that produces summary statistics of the price data by country. 
priceSummary <- selPriceDataIntra %>%
  group_by(Country) %>%
  summarise(Min = min(Quadratic.residSD), Mean = mean(Quadratic.residSD), Median = median(Quadratic.residSD),
            Max = max(Quadratic.residSD), SD = sd(Quadratic.residSD)) %>%
  mutate(CV = SD/Mean) %>%
  mutate_if(is.numeric, round, 2)

# Export to Latex
stargazer(priceSummary, summary = FALSE)

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<#


#-------------------------------------------------------------------------------------------------------------------#
# Construct annual data as control variables. 
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#
# Foreign yield shocks are constructed by through the script "ForeignYieldShockV2.r". 
rm(list = ls())

PriceVolDat <- fread('../5_Data/FAOMaizeMonthPriceDeTrendDeSeason_May2019.csv') %>%
  mutate(ISO = countrycode(Country, 'country.name', 'iso3c'))

# Marketing Year
{
MarketYearMaize <- read_xls('../5_Data/PSD_MarketYear/PSD_MarketYearMaize.xls', sheet = 1, range = 'A2:D227') %>%
  mutate(Commodity = 'Maize') %>%
  filter(grepl('2018', Years)) %>%
  mutate(StartYear = substr(Years, 1, 4), EndYear = substr(Years, 6, 9),
         StartMonth = match(tolower(substr(`Market Year`, 1, 3)), tolower(month.abb)),
         EndMonth = match(tolower(substr(`Market Year`, 8, 10)), tolower(month.abb)),
         YearAdjust = ifelse(substr(`Note`, 6, 9) == substr(`Note`, 35, 38), 'Same', 'Onwards'),
         ISO = countrycode(Country, 'country.name', 'iso3c')) %>%
  dplyr::select(5, 8, 9, 10, 11)

### Add marketing year information to the dataset.
AddDat <- data.frame(matrix(NA, 2, 5))
colnames(AddDat) <- colnames(MarketYearMaize)
AddDat[1, ] <- c('Maize', 7, 6, 'Same', 'SWZ') # Swaiziland
AddDat[2, ] <- c('Maize', 7, 6, 'Same', 'NER') # Niger
AddDat$StartMonth <- as.numeric(AddDat$StartMonth)
AddDat$EndMonth <- as.numeric(AddDat$EndMonth)

MarketYearMaize <- bind_rows(MarketYearMaize, AddDat)
}

# Real exchange rate.
#splineTrendFunc <- function(x, y) lm(x ~ bs(y, 3, degree = 2))$residual

RealExchangeRate0 <- fread('../5_Data/REER_database_ver28Jun2018_Monthly.csv')
colnames(RealExchangeRate0)[1] <- 'Year'

RealExchangeRateVol <- RealExchangeRate0 %>%
  gather(tmp, REERZsolt, 2:ncol(.)) %>%
  filter(!is.na(REERZsolt)) %>%
  mutate(iso2c = substr(tmp, 10, 11),
         ISO = countrycode(iso2c, 'iso2c', 'iso3c'),
         REERZsolt = log(as.numeric(REERZsolt))) %>%
  filter(ISO %in% unique(PriceVolDat$ISO)) %>%
  select(Year, ISO, REERZsolt) %>%
  mutate(Month = as.numeric(substr(Year, 6, 7)),
         Year = as.numeric(substr(Year, 1, 4))) %>%
  filter(Year >= 1999) %>%
  group_by(ISO) %>%
  arrange(ISO, Year, Month, .by_group = T) %>%
  mutate(Trend = 1:n()) %>%
  mutate(#REERZsoltDeTrend = splineTrendFunc(REERZsolt, Trend),
         REERZsoltDeTrend = hpfilter(REERZsolt, type = 'lambda', freq = 129600)$cycle) %>% # Use section X to show the data fitting. 
  left_join(., MarketYearMaize, by = 'ISO') %>%
  mutate(mktYear = ifelse(Month < StartMonth, Year - 1, Year)) %>%
  group_by(ISO, mktYear) %>%
  summarise(REER_SD = sd(REERZsoltDeTrend, na.rm = TRUE))

# # section X
# RealExchangeRateVol %>%
#   mutate(fitted = REERZsolt - REERZsoltDeTrend) %>%
#   ggplot(data = .) +
#   geom_line(aes(Trend, REERZsolt, group = Year)) +
#   geom_line(aes(Trend, fitted, group = Year, col = 'red')) +
#   facet_wrap(~ ISO, scales = 'free')

# Imports and stocks
ImportStock <- fread(input = '../5_Data/PSD_Maize_Rice_Wheat.csv') %>%
  spread(Attribute, Value) %>%
  mutate(Commodity = case_when(grepl('Rice', Commodity)~ 'Rice',
                               grepl('Corn', Commodity)~ 'Maize',
                               TRUE~Commodity)) %>%
  dplyr::filter(Year <= 2017, Commodity %in% c('Maize')) %>%
  mutate(NetImportRatio = (Imports - Exports)/`Domestic Consumption`,
         BeginStockRatio = `Beginning Stocks`/`Domestic Consumption`,
         EndStockRatio = `Ending Stocks`/`Domestic Consumption`) %>%
  mutate(ISO = countrycode(Country, 'country.name', 'iso3c')) %>%
  rename(DomConsump = `Domestic Consumption`) %>%
  dplyr::select(Year, ISO, NetImportRatio, BeginStockRatio, DomConsump, EndStockRatio) %>%
  mutate(StockChange = BeginStockRatio - EndStockRatio)

AnnualData <- RealExchangeRateVol %>%
  left_join(., ImportStock, by = c('mktYear' = 'Year', 'ISO'))

write.csv(AnnualData, file = '../5_Data/RegressionAnnualData_May2019.csv', row.names = F)


# Imports and Domestic Yields. 










